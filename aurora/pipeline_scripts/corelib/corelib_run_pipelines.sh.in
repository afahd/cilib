#!/bin/bash -e

## The purpose of this script is to run all the corelib centric pipelines (the test suites assosiated with each of the pipelines).
## Depending upon the pipeline specified in the parameters, the scripts are generated to be run on the gcloud instances. The scripts
## are then used by aurora run to be executed on the gcloud instances. The results of each iteration of the tests are collected and
## then copied into the developers local machine.

export PATH=@CMAKE_BINARY_DIR@/:/opt/pg/scripts:/opt/pg/scripts/gcloud/aurora/pipeline_scripts/:$PATH
source /home/$USER/.aurora.conf
source pl_utils.sh
source pl_help.sh
source pl_settings.conf
source gc_helpers.sh

#Kill child  processes, if some exist, before exiting.
function exit_handler() {
  [[ -z "$(jobs -p)" ]] || kill -9 $(jobs -p)
}

trap "exit_handler" EXIT

#Show help
if [[ $3 =~ "help" ]]; then
  show_pl_help
  exit 1
fi
BUILD_ENV_USER=${USER}
STEP_ST=1
STEP_ED=7
DEST_SCRIPT_DIR=0

echo "run_pipelines.sh $@"
ARGS=$@
# read the options
TEMP=`getopt -o W:l:P:b:i:f:t:u:s:n:\r:d:IFKc:h --long WORKSPACE:,buildid:,pipeline:,branch:,test_iterations:,first_test:,step_size:,update_db_failure_limit:,script:,num_instances:,base_script_dir:,dest_script_dir:,initial_run,db_update,keep-running,cost_pipeline_code:,\help -n 'run_all_test.sh' -- "$@"`
eval set -- "$TEMP"

# extract options and their arguments into variables.
while true ; do
  case "$1" in
    -W|--WORKSPACE) export WORKSPACE=$2 ; shift 2 ;;
    -l|--buildid) USER_BUILD_ID=$2 ; shift 2 ;;
    -P|--pipeline) PIPELINE=$2 ; shift 2 ;;
    -b|--branch) BRANCH=$2 ; shift 2 ;;
    -i|--test_iterations) TEST_ITERATIONS=$2 ; shift 2 ;;
    -f|--first_test) FIRST_TEST=$2 ; shift 2 ;;
    -t|--step_size) STEP_SIZE=$2 ; shift 2 ;;
    -u|--update_db_failure_limit) UPDATE_DB_FAILURE_LIMIT=$2 ; shift 2 ;;
    -s|--script) USER_SCRIPT=$2 ; shift 2 ;;
    -n|--num_instances) NUM_INSTANCES=$2 ; shift 2 ;;
    -r|--base_script_dir) BASE_SCRIPT_DIR=$2 ; shift 2;;
    -d|--dest_script_dir) DEST_SCRIPT_DIR=$2 ; shift 2;;
    -I|--initial_run) INITIAL_RUN="true" ; shift ;;
    -F|--db_update) DB_UPDATE="true" ; shift ;;
    -K|--keep-running) KEEP_RUNNING="-K"; shift ;;
    -c|--cost_pipeline_code) COST_PIPELINE_CODE="$2" ; shift 2 ;;
    -h|--help)
      show_run_tests_help
      exit 0
      shift ;;
    --) shift ; break ;;
    *)
      echo "Unrecognized option $1"
       exit 1 ;;
  esac
done

mkdir -p ${WORKSPACE}/logs
if [[ -z "$USER_BUILD_ID" ]]; then
  echo "Please supply required "--buildid" argument"
  show_run_tests_help
  exit 1
fi

BUILD_ID=${emailid}-${USER_BUILD_ID}
MOD_BUILD_ID=`echo ${BUILD_ID} | sed 's/bld/run/'`

# TODO: log/untar_log directory is defined in two locations.
script_dir=$(get_script_dir $WORKSPACE $DEST_SCRIPT_DIR $PIPELINE $MOD_BUILD_ID)
log_dir=${script_dir}/logs
untar_log_dir=${script_dir}/untar_logs

echo "run_pipelines.sh $ARGS" > $log_dir/aurora_pipeline_command
db=$(get_db $PIPELINE $BRANCH)
if [[ -e $db ]]; then
  echo "database selected = $db"
else
  echo "$db does not exist!"
  exit 1
fi

#Set the number of iterations
TEST_ITERATIONS=$(set_iteration_count $PIPELINE $TEST_ITERATIONS)
#Set the number of instances
NUM_INSTANCES=$(set_instance_count $PIPELINE $NUM_INSTANCES)

function run_test() {
  local step=$1

  case "$step" in
  1)
    # Generate scripts to be used by "aurora run"
    echo "Going to generate test scripts"
    # [TODO] Add DEBUG-TEST support as well
    gen_test_scripts.sh -p $PIPELINE -b ${BASE_SCRIPT} -i ${TEST_ITERATIONS} -f ${FIRST_TEST} -t ${STEP_SIZE} -n ${NUM_INSTANCES} -d ${script_dir} -I ${INITIAL_RUN} --base_script_dir $BASE_SCRIPT_DIR -D ${db}


    ;;

  2)
    pids=()
    echo "log_dir=$log_dir script_dir=$script_dir"
    while read -r -d $'\0'; do
      aurora run -l ${USER_BUILD_ID} -o ${log_dir} -s $REPLY --cost_pipeline_code $COST_PIPELINE_CODE $KEEP_RUNNING > $REPLY.txt 2>&1 &
      #Get the pid of the last background command
      pids+=("$!")
    done < <(find ${script_dir} -regextype posix-extended  -regex '^.*.sh-[0-9]+$' -print0)
    sleep 30
    ;;

  3)
    pipeline_start_time=$(date +%s)
    echo "Waiting for command to finish ..."
    # Background loop to print the number of aurora_run processes
    while [[ ! -z `pgrep -f "run -l ${USER_BUILD_ID} -o ${log_dir}"` ]]; do
      echo -n "[`pgrep -f \"run -l ${USER_BUILD_ID} -o ${log_dir}\" | wc -l`] ";
      sleep 60 ;
    done &
    echoer_pid=$!
    FAIL=0
    for pid in "${pids[@]}"; do
      wait "$pid" || FAIL=$(($? + $FAIL))
    done
    pipeline_end_time=$(date +%s)
    #Exit if any value is nonzero
    if [[ $FAIL != 0 ]]; then
      #Kill the echo while loop, suppress output
      disown $echoer_pid && kill $echoer_pid
      #Copy the aurora_run logs.
      for file in `ls ${script_dir}/*.txt` ; do
        grep "Run has been completed successfully" $file > /dev/null || cp $file "$WORKSPACE/logs/AURORA.RUN.FAILED.`basename ${file}`"
      done
      echo "Some aurora runs exited unsuccesfully."
      status=1
    else
      #Kill the echo while loop, suppress output
      disown $echoer_pid && kill $echoer_pid
      echo "Aurora run completed successfully."
    fi
    ;;

  4)
    # Start collecting logs
    echo "Copying all logs to ${WORKSPACE}/logs directory"
    find ${log_dir} -name "*${MOD_BUILD_ID}*.tar" -type f -exec tar xf {} -C ${untar_log_dir} \; -exec rm {} \;
    ;;

  5)
     # Generate failed test case report.
    num_failures=$(get_failing_test_number ${untar_log_dir})
    echo "num_failures=$num_failures"
    #Get total tests ran
    local num_total_tests=$(get_total_tests_run ${untar_log_dir})
    echo "Total number of tests run = $num_total_tests"

    if [[ $num_total_tests -eq 0 ]]; then
      status=1
      echo "No tests were run"
    fi

    time_taken=$(print_time_taken $pipeline_start_time $pipeline_end_time "running $PIPELINE pipeline")
    #Create Reports for builder
    generate_status_report "$PIPELINE" "$num_failures" "$num_total_tests" "$time_taken" "${WORKSPACE}/aurora-pipeline-status"
    generate_failing_list "${untar_log_dir}" "${WORKSPACE}/logs/failing-list.log"
    ;;

  6)
    generate_ctest_output ${untar_log_dir} ${WORKSPACE}/logs/ctest_output.log
    if [[ -e ${WORKSPACE}/logs/ctest_output.log ]]; then
      pushd ${WORKSPACE}/logs
      gzip ctest_output.log
      popd
    fi
    ;;
  7)
    #Collect XML logs
    collect_xml_logs "${untar_log_dir}" "${WORKSPACE}/logs/xml_logs/"

    generate_test_directories ${untar_log_dir} ${WORKSPACE}/test_logs

    if [[ "$num_failures" -le "$UPDATE_DB_FAILURE_LIMIT" && $DB_UPDATE == "true" ]];then
      # Update database
      echo "Update database ${db} from ${untar_log_dir}"
      build_db.sh -D ${db} -d ${untar_log_dir} > ${untar_log_dir}/DB_REPORT.txt
      cat ${untar_log_dir}/DB_REPORT.txt
      printf "\n\n******* Updation of database has been completed. Please see ${untar_log_dir}/DB_REPORT.txt ******\n\n"
    fi

    #rm -rf ${untar_log_dir}

    mv ${WORKSPACE}/test_logs  ${WORKSPACE}/logs
    tar czf $script_dir.tar.gz -C $WORKSPACE/ ${script_dir#$WORKSPACE/}
    mv $script_dir.tar.gz ${WORKSPACE}/logs/aurora_infra_logs.tar.gz

    if [[ $num_failures -eq 0 && -z $status ]]; then
      status=0
    else
      status=1
    fi

    rm -rf $script_dir
    return $status
    ;;

  *)
    echo "NOP - $step"
  ;;
  esac
}

script_start_time=$(date +%s)
for STEP in `seq ${STEP_ST} ${STEP_ED}`; do
  printf "\n    === Starting STEP $STEP === \n"
  start_time=$(date +%s)
  run_test $STEP
  end_time=$(date +%s)
  print_time_taken $start_time $end_time "[$STEP]"
done
script_end_time=$(date +%s)
print_time_taken $script_start_time $script_end_time "[RUN]"
