#!/bin/bash -e
export PATH=@CMAKE_BINARY_DIR@/:/opt/pg/scripts:/opt/pg/scripts/gcloud/aurora/pipeline_scripts/:$PATH
source /home/$USER/.aurora.conf
source pl_utils.sh
source pl_help.sh
source pl_settings.conf
source gc_helpers.sh

#Kill child  processes, if some exist, before exiting.
function exit_handler() {
  [[ -z "$(jobs -p)" ]] || kill -9 $(jobs -p)
}

trap "exit_handler" EXIT

#Show help
if [[ $3 == "help" ]]; then
  show_pl_help
  exit 1
fi
BUILD_ENV_USER=${USER}
STEP_ST=1
STEP_ED=7
DEST_SCRIPT_DIR=0

echo "run_pipelines.sh $@"
ARGS=$@
# read the options
TEMP=`getopt -o Q:R:E:W:l:P:b:i:f:t:u:s:n:\r:d:IFKc:e:a:h --long major:,minor_start:,minor_end:,WORKSPACE:,buildid:,pipeline:,branch:,test_iterations:,first_test:,step_size:,update_db_failure_limit:,script:,num_instances:,base_script_dir:,dest_script_dir:,initial_run,db_update,keep-running,local_commit:,existing_commit_hash:,alps-path:,cost_pipeline_code:,\help -n 'run_all_test.sh' -- "$@"`
eval set -- "$TEMP"

# extract options and their arguments into variables.
while true ; do
  case "$1" in
    -Q|--major) MAJOR_STEPS="$2"; shift 2 ;;
    -R|--minor_start ) MINOR_STEPS_ST[$MAJOR_STEPS]="$2"; shift 2 ;;
    -E|--minor_end ) MINOR_STEPS_ED[$MAJOR_STEPS]="$2"; shift 2 ;;
    -W|--WORKSPACE) export WORKSPACE=$2 ; shift 2 ;;
    -l|--buildid) USER_BUILD_ID=$2 ; shift 2 ;;
    -P|--pipeline) PIPELINE=$2 ; shift 2 ;;
    -b|--branch) BRANCH=$2 ; shift 2 ;;
    -i|--test_iterations) TEST_ITERATIONS=$2 ; shift 2 ;;
    -f|--first_test) FIRST_TEST=$2 ; shift 2 ;;
    -t|--step_size) STEP_SIZE=$2 ; shift 2 ;;
    -u|--update_db_failure_limit) UPDATE_DB_FAILURE_LIMIT=$2 ; shift 2 ;;
    -s|--script) USER_SCRIPT=$2 ; shift 2 ;;
    -n|--num_instances) NUM_INSTANCES=$2 ; shift 2 ;;
    -r|--base_script_dir) BASE_SCRIPT_DIR=$2 ; shift 2;;
    -d|--dest_script_dir) DEST_SCRIPT_DIR=$2 ; shift 2;;
    -I|--initial_run) INITIAL_RUN="true" ; shift ;;
    -F|--db_update) DB_UPDATE="true" ; shift ;;
    -K|--keep-running) KEEP_RUNNING="-K"; shift ;;
    #Optional argments for local changes transfer
    -c|--local_commit) LOCAL_COMMIT_HASH="-c $2" ; shift 2 ;;
    -e|--existing_commit_hash) EXISTING_COMMIT_HASH=$2 ; shift 2 ;;
    -a|--alps-path) ALPS_PATH="-a $2" ; shift 2 ;;
    --cost_pipeline_code) COST_PIPELINE_CODE="$2" ; shift 2 ;;
    -h|--help)
      show_run_tests_help
      exit 0
      shift ;;
    --) shift ; break ;;
    *)
      echo "Unrecognized option $1"
       exit 1 ;;
  esac
done

mkdir -p ${WORKSPACE}/logs
if [[ -z "$USER_BUILD_ID" ]]; then
  echo "Please supply required "--buildid" argument"
  show_run_tests_help
  exit 1
fi

BUILD_ID=${emailid}-${USER_BUILD_ID}
MOD_BUILD_ID=`echo ${BUILD_ID} | sed 's/bld/run/'`

# TODO: log/untar_log directory is defined in two locations.
script_dir=$(get_script_dir $WORKSPACE $DEST_SCRIPT_DIR $PIPELINE $MOD_BUILD_ID)
log_dir=${script_dir}/logs
untar_log_dir=${script_dir}/untar_logs

echo "run_pipelines.sh $ARGS" > $log_dir/aurora_pipeline_command
if [[ $PIPELINE == "smoke" || $PIPELINE == "extended" || $PIPELINE == "unstable" || $PIPELINE == "pgui-smoke" || $PIPELINE == "omni" || $PIPELINE == "pgui-extended" ]]; then
  db=$(get_db $PIPELINE $BRANCH)
  if [[ -e $db ]]; then
    echo "database selected = $db"
  else
    echo "$db does not exist!"
    exit 1
  fi
elif [[ $PIPELINE != "DEBUG-TEST" && $PIPELINE != "automaton-longevity" && $PIPELINE != "automaton" && $PIPELINE != "longevity" && $PIPELINE != "coral-smoke" ]]; then
  echo "Invalid Pipeline Specified"
  exit 1
fi

#Set the number of instances and iterations
if [[ -z "$NUM_INSTANCES" ]]; then
  if [[ $PIPELINE == "automaton-longevity" ]]; then
    NUM_INSTANCES=${NUM_AUTOMATON_LONGEVITY_INSTANCES}
  elif [[ $PIPELINE == "automaton" ]]; then
    NUM_INSTANCES=${NUM_AUTOMATON_INSTANCES}
  elif [[ $PIPELINE == "longevity" ]]; then
    NUM_INSTANCES=${NUM_LONGEVITY_INSTANCES}
  elif [[ $PIPELINE == "omni" ]]; then
    NUM_INSTANCES=${OMNI_NUM_INSTANCES}
    TEST_ITERATIONS=${OMNI_TEST_ITERATIONS}
  elif [[ $PIPELINE == "pgui-smoke" ]]; then
    NUM_INSTANCES=${PGUI_NUM_INSTANCES}
  elif [[ $PIPELINE == "pgui-extended" ]]; then
    NUM_INSTANCES=${PGUI_EXTENDED_NUM_INSTANCES}
  else
    NUM_INSTANCES=${NUM_DEFAULT_INSTANCES}
  fi
fi


function run_test() {
  local step=$1

  case "$step" in
  1)
    # Generate scripts to be used by "aurora run"
    echo "Going to generate test scripts"
    if [[ $PIPELINE == "DEBUG-TEST" ]]; then
      echo "pipeline is debug-test"
      gen_user_tests.sh -b ${BASE_SCRIPT} -i ${TEST_ITERATIONS} -n ${NUM_INSTANCES} -d ${script_dir} --base_script_dir ${BASE_SCRIPT_DIR} -s ${USER_SCRIPT}
    elif [[ $PIPELINE == "automaton" || $PIPELINE == "automaton-longevity" || $PIPELINE == "longevity" ]]; then
      gen_automaton_tests.sh -b ${BASE_SCRIPT} -i ${TEST_ITERATIONS} -d ${script_dir} -r $BASE_SCRIPT_DIR -p $PIPELINE -n ${NUM_INSTANCES}
    else
      gen_test_scripts.sh -p $PIPELINE -b ${BASE_SCRIPT} -i ${TEST_ITERATIONS} -f ${FIRST_TEST} -t ${STEP_SIZE} -n ${NUM_INSTANCES} -d ${script_dir} -I ${INITIAL_RUN} --base_script_dir $BASE_SCRIPT_DIR -D ${db}
    fi

    ;;

  2)
    pids=()
    echo "log_dir=$log_dir script_dir=$script_dir"
    while read -r -d $'\0'; do
      aurora run -l ${USER_BUILD_ID} -o ${log_dir} -s $REPLY -e $EXISTING_COMMIT_HASH --cost_pipeline_code $COST_PIPELINE_CODE $KEEP_RUNNING $LOCAL_COMMIT_HASH $ALPS_PATH > $REPLY.txt 2>&1 &
      #Get the pid of the last background command
      pids+=("$!")
    done < <(find ${script_dir} -regextype posix-extended  -regex '^.*.sh-[0-9]+$' -print0)
    sleep 30
    ;;

  3)
    pipeline_start_time=$(date +%s)
    echo "Waiting for command to finish ..."
    # Background loop to print the number of aurora_run processes
    while [[ ! -z `pgrep -f "run -l ${USER_BUILD_ID} -o ${log_dir}"` ]]; do
      echo -n "[`pgrep -f \"run -l ${USER_BUILD_ID} -o ${log_dir}\" | wc -l`] ";
      sleep 60 ;
    done &
    echoer_pid=$!
    FAIL=0
    for pid in "${pids[@]}"; do
      wait "$pid" || FAIL=$(($? + $FAIL))
    done
    pipeline_end_time=$(date +%s)
    #Exit if any value is nonzero
    if [[ $FAIL != 0 ]]; then
      #Kill the echo while loop, suppress output
      disown $echoer_pid && kill $echoer_pid
      #Copy the aurora_run logs.
      for file in `ls ${script_dir}/*.txt` ; do
        grep "Run has been completed successfully" $file > /dev/null || cp $file "$WORKSPACE/logs/AURORA.RUN.FAILED.`basename ${file}`"
      done
      echo "Some aurora runs exited unsuccesfully."
      status=1
    else
      #Kill the echo while loop, suppress output
      disown $echoer_pid && kill $echoer_pid
      echo "Aurora run completed successfully."
    fi
    ;;

  4)
    # Start collecting logs
    echo "Copying all logs to ${WORKSPACE}/logs directory"
    find ${log_dir} -name "*${MOD_BUILD_ID}*.tar" -type f -exec tar xf {} -C ${untar_log_dir} \; -exec rm {} \;
    ;;

  5)
    # Generate failed test case report.
    num_failures=$(find ${untar_log_dir} -name "*FAILED.log" | wc -l)
    test_count=$(find ${untar_log_dir} -name "total_tests_inst*" -type f)
    #Get total tests ran
    local num_total_tests=0
    for file in ${test_count[@]}; do
      num_total_tests=$((`cat $file`+$num_total_tests))
    done
    time_taken=$(print_time_taken $pipeline_start_time $pipeline_end_time "running $PIPELINE pipeline")
    # Write to status file in case of failures
    if [[ ${num_failures} -gt 0 ]]; then
      cat /dev/null > ${WORKSPACE}/logs/failing-list.log
      #Write status for builder script
      echo "$PIPELINE,$time_taken,${num_failures},$num_total_tests" > ${WORKSPACE}/aurora-pipeline-status
      failed_list=$(find ${untar_log_dir} -name "*FAILED.log")
      for test_name in ${failed_list[@]}; do
        test_name=$(basename "$test_name")
        test_name=$(echo "$test_name" | sed 's/ctestout_inst.*_iter[0-9]\+_//' | sed 's/.FAILED.log//' )
        echo "$test_name" >> "${WORKSPACE}/logs/failing-list.log"
      done
    fi
    echo "Total number of tests run = $num_total_tests"

    if [[ $num_total_tests -eq 0 ]]; then
      status=1
      echo "No tests were run"
    fi
    ;;

  6)
    num_failures=$(find ${untar_log_dir} -name "*FAILED.log" | wc -l)
    echo "num_failures=$num_failures"

    #Concatenate all the log files into one file
    for log_file in `find ${untar_log_dir} -type f -name "*.log"` ; do
      cat $log_file >>  ${WORKSPACE}/logs/ctest_output.log
      echo "--------------------------------------" >> ${WORKSPACE}/logs/ctest_output.log
    done
    if [[ -e ${WORKSPACE}/logs/ctest_output.log ]]; then
      pushd ${WORKSPACE}/logs
      gzip ctest_output.log
      popd
    fi
    ;;
  7)
    #Copy the XML logs for omni
    if [[ "$PIPELINE" == "omni" || "$PIPELINE" == "extended" || "$PIPELINE" == "smoke" || "$PIPELINE" == "unstable" ]]; then
      mkdir -p ${WORKSPACE}/logs/xml_logs
      #Replace the '.FAILED' for the failing logs so failing logs take precedence
      find ${untar_log_dir} -type f -name "*FAILED.xml" -exec  rename -f 's/.FAILED.xml/.xml/' '{}' \;
      #Copy the xml logs
      find ${untar_log_dir} -type f -name "*.xml" -exec mv {} ${WORKSPACE}/logs/xml_logs/ \;
    fi

    mkdir -p ${WORKSPACE}/test_logs

    # find all the failed files and copy them to the WORKSPACE
    for file in `find ${untar_log_dir} -type f -name "*FAILED.log" -o -type f -name "*.tar.gz"`; do
      base_test_name=`basename $file`
      #Remove the instance number, iteration number and extension
      pretty_test_name=$(echo "$base_test_name" | sed 's/ctestout_inst.*_iter[0-9]\+_//' | sed 's/.FAILED.log//' | sed 's/.tar.gz//')
      mkdir -p $WORKSPACE/test_logs/$pretty_test_name
      cp $file $WORKSPACE/test_logs/$pretty_test_name/$base_test_name
    done
    if [[ "$num_failures" -le "$UPDATE_DB_FAILURE_LIMIT" && $DB_UPDATE == "true" ]];then
      # Update database
      echo "Update database ${db} from ${untar_log_dir}"
      build_db.sh -D ${db} -d ${untar_log_dir} > ${untar_log_dir}/DB_REPORT.txt
      cat ${untar_log_dir}/DB_REPORT.txt
      printf "\n\n******* Updation of database has been completed. Please see ${untar_log_dir}/DB_REPORT.txt ******\n\n"
    fi

    #rm -rf ${untar_log_dir}

    mv ${WORKSPACE}/test_logs  ${WORKSPACE}/logs
    tar czf $script_dir.tar.gz -C $WORKSPACE/ ${script_dir#$WORKSPACE/}
    mv $script_dir.tar.gz ${WORKSPACE}/logs/aurora_infra_logs.tar.gz

    if [[ $num_failures -eq 0 && -z $status ]]; then
      status=0
    else
      status=1
    fi

    rm -rf $script_dir
    return $status
    ;;

  *)
    echo "NOP - $step"
  ;;
  esac
}

script_start_time=$(date +%s)
for STEP in `seq ${STEP_ST} ${STEP_ED}`; do
  printf "\n    === Starting STEP $STEP === \n"
  start_time=$(date +%s)
  run_test $STEP
  end_time=$(date +%s)
  print_time_taken $start_time $end_time "[$STEP]"
done
script_end_time=$(date +%s)
print_time_taken $script_start_time $script_end_time "[RUN]"
