#!/bin/bash -e

## The purpose of this script is to run all the alps centric pipelines (the test suites assosiated with each of the pipelines).
## Depending upon the pipeline specified in the parameters, the scripts are generated to be run on the gcloud instances. The scripts
## are then used by aurora run to be executed on the gcloud instances. The results of each iteration of the tests are collected and
## then copied into the developers local machine.

export PATH=@CMAKE_BINARY_DIR@/:/opt/pg/scripts:/opt/pg/scripts/gcloud/aurora/pipeline_scripts/:$PATH
source /home/$USER/.aurora.conf
source pl_utils.sh
source pl_help.sh
source pl_settings.conf
source gc_helpers.sh
source aurora_utils.sh

#Kill child  processes, if some exist, before exiting.
function exit_handler() {
  [[ -z "$(jobs -p)" ]] || kill -9 $(jobs -p)
}

trap "exit_handler" EXIT

#Show help
if [[ $3 == "help" ]]; then
  show_pl_help
  exit 1
fi
BUILD_ENV_USER=${USER}
STEP_ST=1
STEP_ED=7
DEST_SCRIPT_DIR=0
PROJECT="alps"

echo "run_pipelines.sh $@"
ARGS=$@
# read the options
TEMP=`getopt -o Q:R:E:W:l:P:b:i:f:t:u:s:n:\r:d:IFKc:e:a:p:h --long major:,preemptible,minor_start:,minor_end:,WORKSPACE:,buildid:,pipeline:,branch:,test_iterations:,first_test:,step_size:,update_db_failure_limit:,script:,num_instances:,base_script_dir:,dest_script_dir:,initial_run,db_update,keep-running,local_commit:,existing_commit_hash:,project:,alps-path:,cost_pipeline_code:,\help -n 'run_all_test.sh' -- "$@"`
eval set -- "$TEMP"

# extract options and their arguments into variables.
while true ; do
  case "$1" in
    -Q|--major) MAJOR_STEPS="$2"; shift 2 ;;
    -R|--minor_start ) MINOR_STEPS_ST[$MAJOR_STEPS]="$2"; shift 2 ;;
    -E|--minor_end ) MINOR_STEPS_ED[$MAJOR_STEPS]="$2"; shift 2 ;;
    -W|--WORKSPACE) export WORKSPACE=$2 ; shift 2 ;;
    -l|--buildid) USER_BUILD_ID=$2 ; shift 2 ;;
    -P|--pipeline) PIPELINE=$2 ; shift 2 ;;
    -p|--project) PROJECT=$2 ; shift 2 ;;
    -b|--branch) BRANCH=$2 ; shift 2 ;;
    -i|--test_iterations) TEST_ITERATIONS=$2 ; shift 2 ;;
    -f|--first_test) FIRST_TEST=$2 ; shift 2 ;;
    -t|--step_size) STEP_SIZE=$2 ; shift 2 ;;
    -u|--update_db_failure_limit) UPDATE_DB_FAILURE_LIMIT=$2 ; shift 2 ;;
    -s|--script) USER_SCRIPT=$2 ; shift 2 ;;
    -n|--num_instances) NUM_INSTANCES=$2 ; shift 2 ;;
    -r|--base_script_dir) BASE_SCRIPT_DIR=$2 ; shift 2;;
    -d|--dest_script_dir) DEST_SCRIPT_DIR=$2 ; shift 2;;
    -I|--initial_run) INITIAL_RUN="true" ; shift ;;
    -F|--db_update) DB_UPDATE="true" ; shift ;;
    -K|--keep-running) KEEP_RUNNING="-K"; shift ;;
    --preemptible) PREEMPTIBLE="1" ; shift ;;
    #Optional argments for local changes transfer
    -c|--local_commit) LOCAL_COMMIT_HASH="-c $2" ; shift 2 ;;
    -e|--existing_commit_hash) EXISTING_COMMIT_HASH=$2 ; shift 2 ;;
    -a|--alps-path) ALPS_PATH="-a $2" ; shift 2 ;;
    --cost_pipeline_code) COST_PIPELINE_CODE="$2" ; shift 2 ;;
    -h|--help)
      show_run_tests_help
      exit 0
      shift ;;
    --) shift ; break ;;
    *)
      echo "Unrecognized option $1"
       exit 1 ;;
  esac
done

mkdir -p ${WORKSPACE}/logs
if [[ -z "$USER_BUILD_ID" ]]; then
  echo "Please supply required "--buildid" argument"
  show_run_tests_help
  exit 1
fi

BUILD_ID=${emailid}-${USER_BUILD_ID}
MOD_BUILD_ID=`echo ${BUILD_ID} | sed 's/bld/run/'`

# TODO: log/untar_log directory is defined in two locations.
script_dir=$(get_script_dir $WORKSPACE $DEST_SCRIPT_DIR $PIPELINE $MOD_BUILD_ID)
log_dir=${script_dir}/logs
untar_log_dir=${script_dir}/untar_logs

echo "run_pipelines.sh $ARGS" > $log_dir/aurora_pipeline_command
if [[ $PROJECT != "alps" ]]; then
  echo "Invalid Project Selected"
  exit 1
fi

if [[ $PIPELINE == "smoke" || $PIPELINE == "extended" || $PIPELINE == "unstable" || $PIPELINE == "pgui-smoke" || $PIPELINE == "omni" || $PIPELINE == "pgui-extended" ]]; then
  db=$(get_db $PIPELINE $BRANCH)
  if [[ -e $db ]]; then
    echo "database selected = $db"
  else
    echo "$db does not exist!"
    exit 1
  fi
elif [[ $PIPELINE != "DEBUG-TEST" && $PIPELINE != "automaton-longevity" && $PIPELINE != "automaton" && $PIPELINE != "longevity" && $PIPELINE != "coral-smoke" && $PIPELINE != "falcon" && $PIPELINE != "falcon-longevity" ]]; then
  echo "Invalid Pipeline Specified"
  exit 1
fi

#Set the number of iterations
TEST_ITERATIONS=$(set_iteration_count $PIPELINE $TEST_ITERATIONS)
#Set the number of instances
NUM_INSTANCES=$(set_instance_count $PIPELINE $NUM_INSTANCES)

function run_test() {
  local step=$1

  case "$step" in
  1)
    # Generate scripts to be used by "aurora run"
    echo "Going to generate test scripts"
    if [[ $PIPELINE == "DEBUG-TEST" ]]; then
      echo "pipeline is debug-test"
      gen_user_tests.sh -b ${BASE_SCRIPT} -i ${TEST_ITERATIONS} -n ${NUM_INSTANCES} -d ${script_dir} --base_script_dir ${BASE_SCRIPT_DIR} -s ${USER_SCRIPT}
    elif [[ $PIPELINE == "automaton" || $PIPELINE == "automaton-longevity" || $PIPELINE == "longevity" || $PIPELINE == "falcon" || $PIPELINE == "falcon-longevity" ]]; then
      gen_automaton_tests.sh -b ${BASE_SCRIPT} -i ${TEST_ITERATIONS} -d ${script_dir} -r $BASE_SCRIPT_DIR -p $PIPELINE -n ${NUM_INSTANCES} -l ${USER_BUILD_ID}
      MACHINE_TYPE="n1-standard-16"
    else
      gen_test_scripts.sh -p $PIPELINE -b ${BASE_SCRIPT} -i ${TEST_ITERATIONS} -f ${FIRST_TEST} -t ${STEP_SIZE} -n ${NUM_INSTANCES} -d ${script_dir} -I ${INITIAL_RUN} --base_script_dir $BASE_SCRIPT_DIR -D ${db}
    fi

    ;;

  2)
    pids=()
    echo "log_dir=$log_dir script_dir=$script_dir"
    while read -r -d $'\0'; do
      if [[ -n "$PREEMPTIBLE" ]]; then
        aurora run_preemptible -l ${USER_BUILD_ID} -o ${log_dir} -s $REPLY -e $EXISTING_COMMIT_HASH -m $MACHINE_TYPE --cost_pipeline_code $COST_PIPELINE_CODE $KEEP_RUNNING $LOCAL_COMMIT_HASH $ALPS_PATH> $REPLY.txt 2>&1 &
      else
        aurora run -l ${USER_BUILD_ID} -o ${log_dir} -s $REPLY -e $EXISTING_COMMIT_HASH -m $MACHINE_TYPE --cost_pipeline_code $COST_PIPELINE_CODE $KEEP_RUNNING $LOCAL_COMMIT_HASH $ALPS_PATH > $REPLY.txt 2>&1 &
      fi
      #Get the pid of the last background command
      pids+=("$!")
    done < <(find ${script_dir} -regextype posix-extended  -regex '^.*.sh-[0-9]+$' -print0)
    sleep 30
    ;;

  3)
    echo "Waiting for command to finish ..."
    print_background_jobs ${USER_BUILD_ID} ${log_dir} &
    echoer_pid=$!
    pipeline_start_time=$(date +%s)

    FAIL=0
    for pid in "${pids[@]}"; do
      wait "$pid" || FAIL=$(($? + $FAIL))
    done

    pipeline_end_time=$(date +%s)
    #Exit if any value is nonzero
    if [[ $FAIL != 0 ]]; then
      #Kill the echo while loop, suppress output
      disown $echoer_pid && kill $echoer_pid || true
      #Copy the aurora_run logs.
      for file in `ls ${script_dir}/*.txt` ; do
        grep "Run has been completed successfully" $file > /dev/null || cp $file "$WORKSPACE/logs/AURORA.RUN.FAILED.`basename ${file}`"
      done
      echo "Some aurora runs exited unsuccesfully."
      status=1
    else
      #Kill the echo while loop, suppress output
      disown $echoer_pid && kill $echoer_pid
      echo "Aurora run completed successfully."
    fi
    ;;

  4)
    # Start collecting logs
    echo "Copying all logs to ${WORKSPACE}/logs directory"
    find ${log_dir} -name "*${MOD_BUILD_ID}*.tar" -type f -exec tar xf {} -C ${untar_log_dir} \; -exec rm {} \;
    ;;

  5)
    # Generate failed test case report.
    num_failures=$(get_failing_test_number ${untar_log_dir})
    echo "num_failures=$num_failures"
    #Get total tests ran
    local num_total_tests=$(get_total_tests_run ${untar_log_dir})
    echo "Total number of tests run = $num_total_tests"

    if [[ $num_total_tests -eq 0 ]]; then
      status=1
      echo "No tests were run"
    fi

    time_taken=$(print_time_taken $pipeline_start_time $pipeline_end_time "running $PIPELINE pipeline")
    #Create Reports for builder
    generate_status_report "$PIPELINE" "$num_failures" "$num_total_tests" "$time_taken" "${WORKSPACE}/aurora-pipeline-status"
    generate_failing_list "${untar_log_dir}" "${WORKSPACE}/logs/failing-list.log"
    ;;

  6)
    generate_ctest_output ${untar_log_dir} ${WORKSPACE}/logs/ctest_output.log
    if [[ -e ${WORKSPACE}/logs/ctest_output.log ]]; then
      pushd ${WORKSPACE}/logs
      gzip ctest_output.log
      popd
    fi
    ;;
  7)
    #Collect XML logs
    if [[ "$PIPELINE" == "omni" || "$PIPELINE" == "extended" || "$PIPELINE" == "smoke" || "$PIPELINE" == "unstable" ]]; then
        collect_xml_logs "${untar_log_dir}" "${WORKSPACE}/logs/xml_logs/"
    fi

    generate_test_directories ${untar_log_dir} ${WORKSPACE}/test_logs

    if [[ "$num_failures" -le "$UPDATE_DB_FAILURE_LIMIT" && $DB_UPDATE == "true" ]];then
      # Update database
      echo "Update database ${db} from ${untar_log_dir}"
      build_db.sh -D ${db} -d ${untar_log_dir} > ${untar_log_dir}/DB_REPORT.txt
      cat ${untar_log_dir}/DB_REPORT.txt
      printf "\n\n******* Updation of database has been completed. Please see ${untar_log_dir}/DB_REPORT.txt ******\n\n"
    fi

    #rm -rf ${untar_log_dir}

    mv ${WORKSPACE}/test_logs  ${WORKSPACE}/logs
    tar czf $script_dir.tar.gz -C $WORKSPACE/ ${script_dir#$WORKSPACE/}
    mv $script_dir.tar.gz ${WORKSPACE}/logs/aurora_infra_logs.tar.gz

    if [[ $num_failures -eq 0 && -z $status ]]; then
      status=0
    else
      status=1
    fi

    rm -rf $script_dir
    return $status
    ;;

  *)
    echo "NOP - $step"
  ;;
  esac
}

script_start_time=$(date +%s)
for STEP in `seq ${STEP_ST} ${STEP_ED}`; do
  printf "\n    === Starting STEP $STEP === \n"
  start_time=$(date +%s)
  run_test $STEP
  end_time=$(date +%s)
  print_time_taken $start_time $end_time "[$STEP]"
done
script_end_time=$(date +%s)
print_time_taken $script_start_time $script_end_time "[RUN]"
